{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Sensors\n",
    "\n",
    "Kevin J. Walchko, 24 Sept 2017\n",
    "\n",
    "---\n",
    "\n",
    "Now let's talk about the iRobot Create 2 we are going to use. There are a variety of sensors available and we will use some, but not all of them.\n",
    "\n",
    "## References\n",
    "\n",
    "- [Dead Reckoning Wikipedia](https://en.wikipedia.org/wiki/Dead_reckoning)\n",
    "- [Interrupts](http://raspi.tv/2013/how-to-use-interrupts-with-python-on-the-raspberry-pi-and-rpi-gpio-part-3)\n",
    "- [wikipedia: Infrared](https://en.wikipedia.org/wiki/Infrared)\n",
    "- [Wikipedia IMU](https://en.wikipedia.org/wiki/Inertial_measurement_unit)\n",
    "- [Kalman Filter](https://en.wikipedia.org/wiki/Kalman_filter)\n",
    "\n",
    "## Software\n",
    "\n",
    "- [pycreate2 python driver you will use](https://pypi.python.org/pypi/pycreate2)\n",
    "- [IMU python driver](https://pypi.python.org/pypi/nxp-imu)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iRobot Create Sensors\n",
    "\n",
    "<img src=\"pics/create.png\" width=\"300px\">\n",
    "\n",
    "For this class we are using an iRobot Create 2 as our robot base. This robot is equiped with several sensors, but the ones we will use the most are:\n",
    "\n",
    "- IR Sensors\n",
    "    - Cliff detectors that detect the floor or the lack of one in the case of stairs\n",
    "    - Light bump detectors (really they are proximity sensors) that can detect objects in front of the roomba out to ~8\"\n",
    "- Physical bump detectors which are switches that detect physical impact on the front bumper\n",
    "- Encoders which return the amount of wheel rotation for the left and right wheels\n",
    "- Internal sensors for voltage and current on the battery and various motors (e.g., wheels, vacuum brush, etc)\n",
    "    - NiMH battery pack with 19 Ahr capacity. You can actually read this and determine how drained the Roomba is.\n",
    "\n",
    "## Infrared Proximity\n",
    "\n",
    "Infrared sensor are a very common type of proximity sensor. They basically send out a beam of modulated infrared light and looks for the returned signal. Sharp makes a wide range of IR sensors for various commercial applications with detection distances ranging from 2 cm to 6 m.\n",
    "\n",
    "<img src=\"pics/ir_sensors.jpg\" width=\"300px\">\n",
    "\n",
    "These sensor return a voltage that corresponds to a measured distance. The typical\n",
    "sensor curve is shown below.\n",
    "\n",
    "<img src=\"pics/ir_range_curve.png\" width=\"400px\">\n",
    "\n",
    "- IR Issues\n",
    "   - IR sensors are suseptable to being washed out by sunlight\n",
    "   - Multipath: IR light from one sensor could be seen by another if the sensors are misaligned or the light bounces off a reflective surface\n",
    "   - IR works best against surfaces that are orthogonal to the sensor, bright surfaces, and reflect IR. *Note:* cardboard is IR transparent, therefore you will not get a reflection off standard brown cardboard box material.\n",
    "\n",
    "## Quaditure Encoders\n",
    "\n",
    "Unfortunately, the Create doesn't have really good encoders like what \n",
    "is discussed here, but this will give you an idea of how they work.\n",
    "\n",
    "<img src=\"pics/usdigital_encoder.jpg\" width=\"300px\">\n",
    "\n",
    "There are many types of encoders, above is a US Digital encoder designed to\n",
    "be mounted on a motor shaft.\n",
    "\n",
    "<img src=\"pics/quadrature_encoder.gif\" width=\"600px\">\n",
    "\n",
    "The optical encoder, shines a series of lights through an encoder disk and\n",
    "the light is detected or not detected on the other side of the encoder disk\n",
    "by some photoreceptors. A quadrature encoder has 2 signals, A and B, which\n",
    "are phased such that they are *never* high or low at the same time. Depending\n",
    "on the phase of the signals, the direction can be determined.\n",
    "\n",
    "<img src=\"pics/quadrature_animation.gif\" width=\"300px\">\n",
    "\n",
    "The animation shows the signals produced from the movement of the motor\n",
    "shaft, with the encoder disk attached to it.\n",
    "\n",
    "<img src=\"pics/quadrature_waveform.gif\" width=\"300px\">\n",
    "\n",
    "Again, the wave form from A and B tells us if the wheel (motor shaft\n",
    "and disk) are moving in the forward or reverse direction. Note that\n",
    "forward/reverse are arbitrary and the engineer needs to determine\n",
    "if CW or CCW is forward or reverse depending on how the sensor was\n",
    "mounted to the robot.\n",
    "\n",
    "<img src=\"pics/quadrature_resolution.gif\" width=\"300px\">\n",
    "\n",
    "The resolution of the encoder is determine by how the 2 signals are\n",
    "read.\n",
    "\n",
    "- reading A and B on rising edge of A gives you the resolution of how many\n",
    "  stripes there are on the disk\n",
    "- reading on the rising and falling edge of A gives you twice the resolution\n",
    "  of the number of stripes on the disk\n",
    "- reading both A and B for both rising and falling edges gives you 4 times\n",
    "  the resolution as the number of stripes on the disk\n",
    "\n",
    "Now, obviously, the last option gives you the greatest resolution and the\n",
    "best performance ... so why wouldn't you do it? If the speed of your\n",
    "microcontroller is too slow and/or the speed of your wheel is too fast, you\n",
    "could get stuck answering interrupts all the time and never doing anything\n",
    "else. You have to balance your system constraints properly.\n",
    "\n",
    "### Python Pseudo Code\n",
    "\n",
    "```python\n",
    "\n",
    "import time\n",
    "from serial import Serial\n",
    "\n",
    "count = 0\n",
    "COUNTS_TO_METERS = 0.001  # this depends on the encoder system\n",
    "\n",
    "def main_loop():\n",
    "ser = Serial('/dev/tty.usbserial0', 115200)\n",
    "\n",
    "while True:\n",
    "  time.sleep(1)  # time depends on speed of robot\n",
    "  position += count * COUNTS_TO_METERS\n",
    "  count = 0\n",
    "\n",
    "  # a super simple serial response to report position\n",
    "  if ser.read() == 'p':\n",
    "    ser.write(position)\n",
    "\n",
    "# an interrupt that gets called every time A or B changes\n",
    "# you can do this with RPi.GPIO on the raspberry pi\n",
    "def interrupt_AB():\n",
    "    A, B = readEncoderPins()\n",
    "    if A ^ B == 1:# Odometry (move to sensors lesson)\n",
    "      count += 1\n",
    "    else:\n",
    "      count -= 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Odometry (Dead Reckoning)\n",
    "\n",
    "A variety of robots are able to determine the distance ($d$) travelled because they have encoders on their wheels (our roomba does) to track the angle the wheel has moved ($\\phi$). This is similar to how cars all come with odometers to show the miles travelled. \n",
    "\n",
    "$$\n",
    "d = r \\phi\n",
    "$$\n",
    "\n",
    "Now the equation above should look familar. If the wheel turns all the way around ($2\\pi$ radians), then that equation becomes the circumference of a circle. If the world was perfect (spoiler, it isn't), then you would get this:\n",
    "\n",
    "![](pics/ideal-odometry.png)\n",
    "\n",
    "By tracking how far each wheel moves, we should be able to determine if a robot is going straight forward, turning to the left in reverse, or whatever. Unfortunately, wheels slip, expecially when it turns, and the distance travelled becomes corrupted. This leads to errors in the true angle of the turn and leads to the following:\n",
    "\n",
    "![](pics/real-odometry.png)\n",
    "\n",
    "This, odometry by itself is often not useful. Even worse, tracking a robot's position by how its wheels perform is not reliable at best. This is one reason why GPS is so useful with robots.\n",
    "\n",
    "![](pics/rover.jpg)\n",
    "\n",
    "The Mars rover uses video odometry to calculate its pose. Stereo cameras identify common features to track (like we did earlier in the vision block) in both the left and right camera. Then computed each feature's 3d position and tracked it from frame to frame to determine the distance and velocity travelled. With proper camera systems, lots of calibration and math, these types of systems are very good.\n",
    "\n",
    "## Encoder Issues\n",
    "\n",
    "    - Wheel slip can cause the encoder to read more distance travelled than what the robot has actually travelled. \n",
    "    - Wheel slip is usually most problematic when a robot turns. The greater the turn, the more slip that occurs, the more the encoders will be off.\n",
    "    - Obviously, robots that must move accross loose dirt (sand dunes on Mars), snow, or whatever will have a discrepency between wheel movement and distance travelled ... even when going straight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Sensors: IMU\n",
    "\n",
    "<img src=\"pics/imu-iso.jpg\" width=\"300px\">\n",
    "\n",
    "Our Creates also have an inertial measurement unit (IMU) attached to the i2c bus of the Raspberry Pi. It uses an interface written for this class called [nxp_imu](https://pypi.python.org/pypi/nxp-imu). Our IMU is actually composed of 2 different IC chips that do different things.\n",
    "\n",
    "### FXOS8700 3-Axis Accelerometer/Magnetometer\n",
    "\n",
    "- 2-3.6V Supply\n",
    "- ±2 g/±4 g/±8 g adjustable acceleration range\n",
    "- ±1200 µT magnetic sensor range\n",
    "- Output data rates (ODR) from 1.563 Hz to 800 Hz\n",
    "- 14-bit ADC resolution for acceleration measurements\n",
    "- 16-bit ADC resolution for magnetic measurements\n",
    "\n",
    "### FXAS21002 3-Axis Gyroscope\n",
    "\n",
    "- 2-3.6V Supply\n",
    "- ±250/500/1000/2000°/s configurable range\n",
    "- Output Data Rates (ODR) from 12.5 to 800 Hz\n",
    "- 16-bit digital output resolution\n",
    "- 192 bytes FIFO buffer (32 X/Y/Z samples)\n",
    "\n",
    "Simple example `python` code to read the IMU is:\n",
    "\n",
    "```python\n",
    "from __future__ import division, print_function\n",
    "from nxp_imu import IMU\n",
    "\n",
    "# set your accels to 4 g's range and gyros to 2000 dps\n",
    "imu = IMU(gs=4, dps=2000)\n",
    "\n",
    "# now grab some data\n",
    "# each of these is an array of [x,y,z]\n",
    "accel, mag, gyro = imu.get()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Create 2 Sensors\n",
    "\n",
    "To work the iRobot Create 2, we will use a library called [pycreate2](https://pypi.python.org/pypi/pycreate2) which was developed for this class. I suggest you take a look at the examples to help you write your code.\n",
    "\n",
    "```python\n",
    "from pycreate2 import Create2\n",
    "\n",
    "# let's create a roomba instance and let it know what serial port to use\n",
    "bot = Create2(port='/dev/ttyS0')\n",
    "bot.start()\n",
    "\n",
    "# the roomba has several modes, we will stay in safe mode\n",
    "bot.safe()\n",
    "\n",
    "# let's read some sensors\n",
    "sensors = bot.get_sensors()\n",
    "print(sensors)\n",
    "```\n",
    "\n",
    "In the above code, `sensors` is a python `namedtuple` with the following keys and values:\n",
    "\n",
    "| Sensor Key Name              | Range             | Index |\n",
    "|------------------------------|-------------------|-------|\n",
    "| bumps\\_wheeldrops            | \\[0-15\\]          | 0     |\n",
    "| wall                         | \\[0-1\\]           | 1     |\n",
    "| cliff\\_left                  | \\[0-1\\]           | 2     |\n",
    "| cliff\\_front\\_left           | \\[0-1\\]           | 3     |\n",
    "| cliff\\_front\\_right          | \\[0-1\\]           | 4     |\n",
    "| cliff\\_right                 | \\[0-1\\]           | 5     |\n",
    "| virtual\\_wall                | \\[0-1\\]           | 6     |\n",
    "| overcurrents                 | \\[0-29\\]          | 7     |\n",
    "| dirt\\_detect                 | \\[0-255\\]         | 8     |\n",
    "| ir\\_opcode                   | \\[0-255\\]         | 9     |\n",
    "| buttons                      | \\[0-255\\]         | 10    |\n",
    "| distance                     | \\[-322768-32767\\] | 11    |\n",
    "| angle                        | \\[-322768-32767\\] | 12    |\n",
    "| charger\\_state               | \\[0-6\\]           | 13    |\n",
    "| voltage                      | \\[0-65535\\]       | 14    |\n",
    "| current                      | \\[-322768-32767\\] | 15    |\n",
    "| temperature                  | \\[-128-127\\]      | 16    |\n",
    "| battery\\_charge              | \\[0-65535\\]       | 17    |\n",
    "| battery\\_capacity            | \\[0-65535\\]       | 18    |\n",
    "| wall\\_signal                 | \\[0-1023\\]        | 19    |\n",
    "| cliff\\_left\\_signal          | \\[0-4095\\]        | 20    |\n",
    "| cliff\\_front\\_left\\_signal   | \\[0-4095\\]        | 21    |\n",
    "| cliff\\_front\\_right\\_signal  | \\[0-4095\\]        | 22    |\n",
    "| cliff\\_right\\_signal         | \\[0-4095\\]        | 23    |\n",
    "| charger\\_available           | \\[0-3\\]           | 24    |\n",
    "| open\\_interface\\_mode        | \\[0-3\\]           | 25    |\n",
    "| song\\_number                 | \\[0-4\\]           | 26    |\n",
    "| song\\_playing                | \\[0-1\\]           | 27    |\n",
    "| oi\\_stream\\_num\\_packets     | \\[0-108\\]         | 28    |\n",
    "| velocity                     | \\[-500-500\\]      | 29    |\n",
    "| radius                       | \\[-322768-32767\\] | 30    |\n",
    "| velocity\\_right              | \\[-500-500\\]      | 31    |\n",
    "| velocity\\_left               | \\[-500-500\\]      | 32    |\n",
    "| encoder\\_counts\\_left        | \\[-322768-32767\\] | 33    |\n",
    "| encoder\\_counts\\_right       | \\[-322768-32767\\] | 34    |\n",
    "| light\\_bumper                | \\[0-127\\]         | 35    |\n",
    "| light\\_bumper\\_left          | \\[0-4095\\]        | 36    |\n",
    "| light\\_bumper\\_front\\_left   | \\[0-4095\\]        | 37    |\n",
    "| light\\_bumper\\_center\\_left  | \\[0-4095\\]        | 38    |\n",
    "| light\\_bumper\\_center\\_right | \\[0-4095\\]        | 39    |\n",
    "| light\\_bumper\\_front\\_right  | \\[0-4095\\]        | 40    |\n",
    "| light\\_bumper\\_right         | \\[0-4095\\]        | 41    |\n",
    "| ir\\_opcode\\_left             | \\[0-255\\]         | 42    |\n",
    "| ir\\_opcode\\_right            | \\[0-255\\]         | 43    |\n",
    "| left\\_motor\\_current         | \\[-322768-32767\\] | 44    |\n",
    "| right\\_motor\\_current        | \\[-322768-32767\\] | 45    |\n",
    "| main\\_brush\\_current         | \\[-322768-32767\\] | 46    |\n",
    "| side\\_brush\\_current         | \\[-322768-32767\\] | 47    |\n",
    "| statis                       | \\[0-3\\]           | 48    |\n",
    "\n",
    "So you can access the sensor values in one of 2 ways:\n",
    "\n",
    "```python\n",
    "d = sensors.distance\n",
    "d = sensors[11]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Files\n",
    "\n",
    "Typically when you build things (i.e., robots, airplanes, satellites, etc) you rarely get to test the entire thing. Instead, if you are building a targeting system for an aircraft, you work with pre-recorded data (from a radar that was flying in another aircraft) and ensure your targeting system interacts with that \"canned\" data properly.\n",
    "\n",
    "We will do the same here. You will play with some pre-recorded data from the roomba and try to understand what is going on. This will help you when you get to work with the real roomba. `bagit` stores data in a json file with optional compression. The idea of `bagit` comes from [ROS bag files](http://wiki.ros.org/Bags). Basically you do:\n",
    "\n",
    "- Create a bag file to save data\n",
    "    - collect data from your robot and store it in a python `dict`\n",
    "    - then use `BagWriter` object to write the `dict` to a file\n",
    "    - if any of the data is a camera image, you have to tell `BagWriter` so It can properly handle the binary image data\n",
    "- Read data from a bag file\n",
    "    - use a `BagReader` to read a bag file\n",
    "    - the `BagReader` will return a `dict` containing all of the data. *Note:* camera images are automagically returned to standard OpenCV `numpy` arrays.\n",
    "    \n",
    "```python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from the_collector.bagit import BagWriter\n",
    "import time\n",
    "\n",
    "filename = 'my_file.json'\n",
    "\n",
    "# create the writer\n",
    "bag = BagWriter()\n",
    "\n",
    "# filename is the bag file we will save it too\n",
    "# 'sam' and 'bob' are just the keys in the dict we will say data too\n",
    "bag.open(['sam', 'bob'])\n",
    "\n",
    "# let's make a bunch of bogus data ... pretend this is real robot stuff!\n",
    "# when you push data to the bag, it records the data with a timestamp\n",
    "for i in range(10):\n",
    "    bag.push('bob', i)        # save some data\n",
    "    bag.push('sam', [i, i+1]) # save some more data\n",
    "    time.sleep(0.1)\n",
    "\n",
    "bag.write(filename)  # now save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- bob -----------------\n",
      "(1508528370.255, 0)\n",
      "(1508528370.385, 1)\n",
      "(1508528370.495, 2)\n",
      "(1508528370.566, 3)\n",
      "(1508528370.696, 4)\n",
      "(1508528370.805, 5)\n",
      "(1508528370.915, 6)\n",
      "(1508528371.024, 7)\n",
      "(1508528371.133, 8)\n",
      "(1508528371.242, 9)\n",
      "\n",
      "-- sam -----------------\n",
      "(1508528370.255, [0, 1])\n",
      "(1508528370.385, [1, 2])\n",
      "(1508528370.495, [2, 3])\n",
      "(1508528370.566, [3, 4])\n",
      "(1508528370.696, [4, 5])\n",
      "(1508528370.805, [5, 6])\n",
      "(1508528370.915, [6, 7])\n",
      "(1508528371.024, [7, 8])\n",
      "(1508528371.133, [8, 9])\n",
      "(1508528371.242, [9, 10])\n",
      "\n",
      "-- b64keys -----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from the_collector.bagit import BagReader\n",
    "\n",
    "reader = BagReader()\n",
    "data = reader.load(filename)  # read in the file and conver to dict\n",
    "\n",
    "# now print everything out\n",
    "for key, value in data.items():\n",
    "        print('-- {} -----------------'.format(key))\n",
    "        for sample in value:\n",
    "                point, timestamp = sample\n",
    "                print(timestamp, point)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our two data items `bob` and `tom` which each contain 10 data points with timestamps. The timestamps are in seconds, which hopefully should make sense since we paused a 1/10 of a second between data samples. It won't be perfect, because there is some overhead in moving data around and recording it. C/C++ would be faster, but python is far easier to develop with.\n",
    "\n",
    "Finally note the last key `b64keys` is empty ... no data. That is an internal data item you don't need to worry about. It basically tracks if there were any binary opencv images that needed to be properly packed for storage or unpacked for retreval.\n",
    "\n",
    "Now, `bagit` stores data as a [json](https://en.wikipedia.org/wiki/JSON) file which is by default simple text. You can see this by taking a look at the file using the `cat` command. You can even run this command from this notebook as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is BC17-351A\n",
      "\n",
      " Directory of C:\\Users\\Kevin.Walchko\\github\\ece387\\website\\block_4_mobile_robotics\\lsn27\n",
      "\n",
      "10/20/2017  01:36 PM    <DIR>          .\n",
      "10/20/2017  01:36 PM    <DIR>          ..\n",
      "10/20/2017  12:44 PM    <DIR>          .ipynb_checkpoints\n",
      "10/20/2017  01:36 PM            14,957 lsn27-roomba-overview.ipynb\n",
      "10/20/2017  01:23 PM               500 my_file.json\n",
      "10/16/2017  11:55 AM    <DIR>          pics\n",
      "               2 File(s)         15,457 bytes\n",
      "               4 Dir(s)  107,967,614,976 bytes free\n"
     ]
    }
   ],
   "source": [
    "# let's make sure the file is in the current directory\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"bob\": [[0, 1508527414.302], [1, 1508527414.402], [2, 1508527414.539], [3, 1508527414.61], [4, 1508527414.752], [5, 1508527414.861], [6, 1508527414.97], [7, 1508527415.079], [8, 1508527415.189], [9, 1508527415.298]], \"sam\": [[[0, 1], 1508527414.302], [[1, 2], 1508527414.402], [[2, 3], 1508527414.539], [[3, 4], 1508527414.61], [[4, 5], 1508527414.752], [[5, 6], 1508527414.861], [[6, 7], 1508527414.97], [[7, 8], 1508527415.079], [[8, 9], 1508527415.189], [[9, 10], 1508527415.298]], \"b64keys\": []}\n"
     ]
    }
   ],
   "source": [
    "# now let's read the file\n",
    "!cat my_file.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice our `dict` keys and data points with timestamps. There is also an optional flag to use compresson on these files to reduce size, but then you can't read them like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "- Try creating and reading your own bag file\n",
    "\n",
    "# Questions\n",
    "\n",
    "1. How do infra red sensors work?\n",
    "1. How do quadriture encoders work?\n",
    "1. What are some problems/issues with wheel encoders and dead reckoning?\n",
    "1. What is a bag file and how does it work?\n",
    "1. How do you use the roomba software to read its voltage and current?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "-----------\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
